思想： 奥卡姆剃刀原则（越简单越有效），要尽量减少无用特征（即让它的系数为0或趋0）带来的影响。相当于自动的特征提取。
方式：损失函数加上正则化函数， 正则化函数要满足值越小特征越少（即越简单）的特点。
L0范数: 向量中非0元素的个数（非0元素越少，即0越多，模型越简单， 没毛病！）
L1范数(Lasso): 向量中各元素的绝对值只和
L2范数(Ridge):
补充知识：
1. L1是L0的最优凸近似
什么是最优凸近似
为什么L1是L0的最优凸近似

而从贝叶斯的观点来看，正则化则是在模型参数上引入了某种先验的分布，可以表示为权值w上的零均值高斯先验分布的负对数（详见PRML）。这样就可以将人对这个模型的先验知识融入到模型的学习当中，强行地让学习到的模型具有人想要的特性，例如稀疏、低秩、平滑等等。
解释?
